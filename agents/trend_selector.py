"""–ê–≥–µ–Ω—Ç 3: Trend Selector

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ NewsRaw, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ—Ç –ø–æ —Ç–µ–º–∞–º
–∏ –≤—ã–±–∏—Ä–∞–µ—Ç TOP-5 —Ç—Ä–µ–Ω–¥–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤.
"""

from typing import List, Dict, Tuple
from collections import defaultdict
from datetime import datetime
import re

from utils import setup_logger
from storage.google_sheets import get_sheets_client


# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–∞–º
TOPIC_KEYWORDS = {
    "AI Models": ["gpt", "model", "llm", "transformer", "diffusion", "claude", "gemini", "llama"],
    "AI Agents": ["agent", "autonomous", "workflow", "automation", "copilot", "assistant"],
    "AI Regulation": ["regulation", "policy", "law", "eu ai act", "safety", "governance"],
    "AI Business": ["investment", "funding", "acquisition", "valuation", "revenue", "market"],
    "AI Research": ["paper", "research", "benchmark", "accuracy", "performance", "state-of-the-art"],
    "AI Hardware": ["gpu", "tpu", "chip", "nvidia", "amd", "intel", "hardware", "compute"],
    "AI Open Source": ["open source", "github", "hugging face", "release", "library", "framework"],
    "AI Ethics": ["bias", "ethics", "fairness", "privacy", "misuse", "dangerous"],
}

# –ë—Ä–µ–Ω–¥—ã —Å –≤—ã—Å–æ–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º (—Ö–∞–π–ø)
HIGH_PRIORITY_BRANDS = ["OpenAI", "Google", "Anthropic", "Meta", "Microsoft", "NVIDIA"]


class TrendSelector:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ç—Ä–µ–Ω–¥–æ–≤ –∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        self.logger = setup_logger("TrendSelector", "trend_selector.log")
        self.sheets_client = get_sheets_client()
    
    def _classify_topic(self, text: str) -> str:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ —Ç–µ–º–∞–º.
        
        Args:
            text: –¢–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏
        
        Returns:
            –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã
        """
        text_lower = text.lower()
        
        for topic, keywords in TOPIC_KEYWORDS.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return topic
        
        return "AI General"  # –¢–µ–º–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _calculate_score(
        self,
        cluster: List[Dict],
        topic: str
    ) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç score –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞ —Ç—Ä–µ–Ω–¥–æ–≤.
        
        –§–æ—Ä–º—É–ª–∞: —á–∞—Å—Ç–æ—Ç–∞ + –±—Ä–µ–Ω–¥_–±–æ–Ω—É—Å + –Ω–æ–≤–∏–∑–Ω–∞
        
        Args:
            cluster: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ
            topic: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã
        
        Returns:
            Score —Ç—Ä–µ–Ω–¥–∞
        """
        # –ß–∞—Å—Ç–æ—Ç–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π (–≤–µ—Å 1.0)
        frequency_score = len(cluster)
        
        # –ë—Ä–µ–Ω–¥ –±–æ–Ω—É—Å (–≤–µ—Å 2.0)
        brand_score = 0
        for news in cluster:
            brand = news.get("brand", "")
            if brand and brand in HIGH_PRIORITY_BRANDS:
                brand_score += 2
        
        # –ù–æ–≤–∏–∑–Ω–∞ (–≤–µ—Å 0.5) - —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤–∞–∂–Ω–µ–µ
        recency_score = 0
        now = datetime.now()
        for news in cluster:
            try:
                pub_date = datetime.strptime(news.get("published_at", ""), "%Y-%m-%d %H:%M:%S")
                hours_diff = (now - pub_date).total_seconds() / 3600
                # –ß–µ–º —Å–≤–µ–∂–µ–µ, —Ç–µ–º –≤—ã—à–µ score (–º–∞–∫—Å–∏–º—É–º 1.0)
                recency_score += max(0, 1 - hours_diff / 24) * 0.5
            except (ValueError, TypeError):
                recency_score += 0.25  # –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –µ—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞
        
        total_score = frequency_score + brand_score + recency_score
        self.logger.debug(f"Topic '{topic}': freq={frequency_score}, brand={brand_score}, recency={recency_score:.2f}, total={total_score:.2f}")
        
        return total_score
    
    def _generate_description(self, cluster: List[Dict], topic: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ.
        
        Args:
            cluster: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
            topic: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã
        
        Returns:
            –û–ø–∏—Å–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
        """
        # –ë–µ—Ä—ë–º —Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
        titles = [news.get("title", "") for news in cluster[:3]]
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±—Ä–µ–Ω–¥—ã
        brands = set()
        for news in cluster:
            brand = news.get("brand", "")
            if brand:
                brands.add(brand)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
        brands_str = ", ".join(brands) if brands else "Various companies"
        count = len(cluster)
        
        description = f"{topic}: {count} –Ω–æ–≤–æ—Å—Ç–µ–π –æ—Ç {brands_str}. –ö–ª—é—á–µ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è: {'; '.join(titles[:2])}"
        
        return description[:300]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    
    def cluster_news(self, records: List[Dict]) -> Dict[str, List[Dict]]:
        """
        –ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–µ–º–∞–º.
        
        Args:
            records: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ NewsRaw
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å {topic: [news_records]}
        """
        clusters = defaultdict(list)
        
        for record in records:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º title –∏ summary –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            text = f"{record.get('title', '')} {record.get('summary', '')}"
            topic = self._classify_topic(text)
            clusters[topic].append(record)
        
        self.logger.info(f"–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {len(clusters)}")
        for topic, news in clusters.items():
            self.logger.info(f"  {topic}: {len(news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        return dict(clusters)
    
    def select_top_trends(
        self,
        clusters: Dict[str, List[Dict]],
        top_n: int = 5
    ) -> List[Dict]:
        """
        –í—ã–±–∏—Ä–∞–µ—Ç TOP-N —Ç—Ä–µ–Ω–¥–æ–≤ –ø–æ score.
        
        Args:
            clusters: –°–ª–æ–≤–∞—Ä—å –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–Ω–¥–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç—Ä–µ–Ω–¥–æ–≤ [{title, description, score, count}]
        """
        trends = []
        
        for topic, cluster in clusters.items():
            score = self._calculate_score(cluster, topic)
            description = self._generate_description(cluster, topic)
            
            trends.append({
                "title": topic,
                "description": description,
                "score": score,
                "count": len(cluster),
                "news": cluster  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä–∞
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score (—É–±—ã–≤–∞–Ω–∏–µ)
        trends.sort(key=lambda x: x["score"], reverse=True)
        
        top_trends = trends[:top_n]
        self.logger.info(f"–í—ã–±—Ä–∞–Ω–æ TOP-{top_n} —Ç—Ä–µ–Ω–¥–æ–≤")
        
        return top_trends
    
    def generate_trends_md(self, trends: List[Dict], output_path: str = "trends.md") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç trends.md —Ñ–∞–π–ª.
        
        Args:
            trends: –°–ø–∏—Å–æ–∫ —Ç—Ä–µ–Ω–¥–æ–≤
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        
        Returns:
            –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        """
        lines = [
            "# üî• TOP-5 AI Trends",
            "",
            f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "---",
            ""
        ]
        
        for i, trend in enumerate(trends, 1):
            lines.append(f"## {i}. {trend['title']}")
            lines.append("")
            lines.append(f"**Score:** {trend['score']:.1f} | **News:** {trend['count']}")
            lines.append("")
            lines.append(f"{trend['description']}")
            lines.append("")
            lines.append("---")
            lines.append("")
        
        content = "\n".join(lines)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(content)
        
        self.logger.info(f"–°–æ—Ö—Ä–∞–Ω—ë–Ω {output_path}")
        
        return content
    
    def run(self) -> List[Dict]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –≤—ã–±–æ—Ä–∞ —Ç—Ä–µ–Ω–¥–æ–≤.
        
        Returns:
            –°–ø–∏—Å–æ–∫ TOP-5 —Ç—Ä–µ–Ω–¥–æ–≤
        """
        self.logger.info("=== –ó–∞–ø—É—Å–∫ Trend Selector ===")
        
        # –ß–∏—Ç–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
        records = self.sheets_client.get_today_records("NewsRaw", "date")
        self.logger.info(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π –∑–∞ —Å–µ–≥–æ–¥–Ω—è: {len(records)}")
        
        if not records:
            self.logger.warning("–ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –∑–∞ —Å–µ–≥–æ–¥–Ω—è")
            return []
        
        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ–º
        clusters = self.cluster_news(records)
        
        # –í—ã–±–∏—Ä–∞–µ–º TOP-5
        top_trends = self.select_top_trends(clusters, top_n=5)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º trends.md
        if top_trends:
            self.generate_trends_md(top_trends)
        
        return top_trends


def run_trend_selector() -> List[Dict]:
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–∞"""
    selector = TrendSelector()
    return selector.run()


if __name__ == "__main__":
    trends = run_trend_selector()
    print(f"Trend Selector –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É. –í—ã–±—Ä–∞–Ω–æ —Ç—Ä–µ–Ω–¥–æ–≤: {len(trends)}")
    for i, trend in enumerate(trends, 1):
        print(f"  {i}. {trend['title']} (score: {trend['score']:.1f})")
